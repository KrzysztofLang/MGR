%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% %
%%% % Mag.tex
%%% % Praca dyplomowa magisterska
%%% % Krzysztof Lang, 148853
%%% %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt,twoside]{article}

\usepackage[section]{placeins}
\usepackage{weiiszablon}

\author{Krzysztof Lang}

% np. EF-123456, EN-654321, ...
\studentID{EF-148853}

\title{Implementacja wybranych algorytmów wypełniania brakujących wartości, dla strumieni dużych zbiorów danych}
\titleEN{Implemetation of selected missing value imputation algorithms for large data sets}


%%% wybierz rodzaj pracy wpisując jeden z poniższych numerów: ...
% 1 = inżynierska	% BSc
% 2 = magisterska	% MSc
% 3 = doktorska		% PhD
%%% na miejsce zera w linijce poniżej
\newcommand{\rodzajPracyNo}{2}


%%% promotor
\supervisor{dr Michał Piętal}
%% przykład: dr hab. inż. Józef Nowak, prof. PRz

%%% promotor ze stopniami naukowymi po angielsku
\supervisorEN{Michał Piętal, PhD}

\abstract{Dla poprawnej analizy danych ważna jest jej kompletność.
Istnieje wiele sposobów radzenia sobie z brakującymi danymi.
Najprostsze metody opierające się między innymi na średniej bądź najczęściej występującej wartości w wielu przypadkach
mogą negatywnie wpłynąć na skuteczność analizy. Niniejsza praca ma na celu przeanalizować skuteczność uzupełniania
brakujących danych z użyciem bardziej zaawansowanych metod opierających się na wykorzystaniu uczenia maszynowego.
Te metody mają na celu wypełnić brakujące dane wartościami dużo bardziej zbliżonymi do rzeczywistych,
minimalizując negatywny wpływ na skuteczność późniejszej analizy danych.}
\abstractEN{For correct data analysis, completeness is important. There are many ways to deal with missing data.
The simplest methods based on, among other things, the average or the most frequently occurring value
in many cases can negatively affect the effectiveness of the analysis. This thesis aims to analyze the effectiveness
of imputing missing data using more advanced methods based on the use of machine learning.
These methods are designed to impute missing data with values much closer to the actual data,
minimizing the negative impact on the effectiveness of subsequent data analysis.}

\begin{document}

% strona tytułowa
\maketitle

\blankpage

% spis treści
\tableofcontents
\clearpage
\blankpage


\section{Wstęp}

W pracy opisano znaczenie wypełniania brakujących wartości w dużych zbiorach danych.
Przedstawiono 3 algorytmy służące wypełnianiu brakujących danych, które następnie zostały zaimplementowane z użyciem
stworzonej na te potrzeby aplikacji. Dokonano porównania dokładności wypełniania danych dla poszczególnych algorytmów
i przeanalizowano uzyskane wyniki. Do przygotowania aplikacji wykorzystano język programowania Python \cite{python},
z wykorzystaniem bibliotek służących do analiz i manipulacji danymi: Pandas \cite{pandas},
NumPy \cite{numpy} i SciKit-learn \cite{scikit} oraz biblioteki
udostęniającej narzędzia do przygotowania interfejsu graficznego EasyGUI \cite{easygui}.
Dane wykorzystane do testów pochodzą z repozytorium danych do uczenia maszynowego
Uniwersytetu Kalifornijskiego w Irvine \cite{uci} oraz zbioru baz danych
udostęnionych w serwisie Kaggle.com  \cite{kaggle}.

W pierwszym rozdziale przedstawiono zarys treści dalszej pracy.
W drugim rozdziale przybliżono ideę wypełniania brakujących wartości w duzych zbiorach danych,
na co składa się rys historyczny zagadnienia, przedstawienie istniejących rozwiązań i ich znaczenie,
oraz zastanowiono się nad przyszłością zagadnienia.
Trzeci rozdział przybliża narzędzia użyte do przygotowania części praktycznej niniejszej pracy,
to jest programu realizującego testy algorytmów wypełniajacych puste miejsca oraz
dane wykorzystane do testów.
Na rodział czwarty składa się opis praktycznej części badań.
Znajduje się w nim opis przygotowanego programu wraz z przykładem działana, opisy zaimplementowanych algorytmów,
oraz przedstawione zostały wyniki przeprowadzonych testów.
Rozdział piąty składa się z podsumowania przeprowadzonych analiz i przedstawienia wyciągniętych wniosków.

\clearpage


\section{Wprowadzenie}

\subsection{Problematyka wypełniania brakujących wartości}

Brakujące wartości są częstym problemem występującym w wielu dziedzinach,
szczególnie tych operujacych na dużych bazach danych. Utrudniają one analizę zebranych informacji,
pogarszając wartość danych. Przykładowe rodzaje danych dla których może to mieć znaczenie to między innymi:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item dane finansowe, gdzie dane wykorzystywane są między innymi do przewidywania zachowania rynków, \cite{fin}
    \item dane medyczne, gdzie dane wykorzystywane są między innymi do pracy nad nowymi lekami i terapiami, \cite{med}
    \item dane statystyczne dotyczące populacji, których analiza może być wykorzystana
          do planowania inwestycji w miastach, \cite{pop}
    \item dane o ruchu sieciowym, mogące posłużyć do wykrywania problemów w sieci czy zapobiegania atakom. \cite{net}
\end{itemize}

Powyższe przykłady to tylko drobny wycinek potencjalnych zastosowań analizy dużych zbiorów danych,
dla których jej dokładność jest kluczowa.

Braki w danych mogą występować z różnych powodów, mogą pojawiać się zarówno podczas samego zbierania danych jak i później.
Przykładowymi źródłami brakujących danych są:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item błędy w sposobie zbierania danych,
    \item niepoprawnie zaprojektowana baza danych,
    \item uszkodzenie nośnika danych,
    \item błędy wynikające z niepoprawnego importu danych,
    \item czynnik ludzki,
    \item uszkodzone instrumenty zbierające dane.
\end{itemize}

Brakujące dane można zakwalifikować do jednego z 3 typów \cite{types}:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item MCAR (ang. missing completly at random) -- brakujące w pełni losowo. Oznacza to,
          że brakujące wartości rozmieszczone są losowo, bez powiązania z innymi danymi.
    \item MAR (ang. missing at random) -- brakujące losowo. Takie dane rozmieszczone są losowo,
          lecz widoczne jest powiązanie z innymi danymi.
    \item MNAR (ang. missing not at random) -- brakujące w sposób nielosowy. Oznacza to,
          że brakujące wartości można powiązać z innymi danymi.
\end{enumerate}

Historia prób wypełniania brakujących wartości sięga wczesnych lat XX wieku.
Wtedy statystycy tacy jak Ronald Fisher i Edwin Wilson zaproponowali metody oparte o średnią i medianę
rozpatrywanych danych. Te metody są stosowane do dziś w niektórych przypadkach, na przykład gdy dane zaliczają się do kategorii
MCAR. \cite{fisher}\cite{wilson}

Dużym przełomem dla wypełniania brakujących danych była publikacja pracy Donalda Rubina pod koniec XX wieku.
Zaprezentowano w niej koncept wielokrotnej imputacji (MI, ang. multiple imputation).
Polega on na generowaniu kilku zestawów danych z imputowanymi wartościami na podstawie rozkładu
wielowymiarowego danych. Następnie stosuje się metodę statystyczną do każdego zestawu danych i łączy się wyniki,
aby uzyskać oszacowania parametrów i ich błędy. \cite{rubin}

Od tego czasu medoda wielokrotnej imputacji stała się populkarnym sposobem uzupełniania brakujących danych
w wielu dziedzinach. \cite{multi}

\subsection{Korzyści i zagrożenia}

Różne metody wypełniania są przydatne dla różnych zastosowań. Wśród nich jest zwiększanie jakości danych,
ułatwienie bądź umożliwienie przeprowadzenia analizy danych, zwiększenie wydajności systemów korzystających z danych.
Należy jednak mieć na uwadze potencjalne zagrożenia wynikające ze sztucznego tworzenia danych,
jak to ma miejsce w przypadku wypełniania.
Aby zminimalizować ryzyko pogorszenia zamiast poprawienia jakości zbioru danych należy dostosować wykorzystane metody
do charakteru danych. Należy brać pod uwagę:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item ilość brakujących danych -- bardzo duże braki mogą nawet uniemożliwić poprawne wypełnianie,
    \item rodzaj danych -- przykładowo dane liczbowe wymagają zastosowania innych metod niż kategoryczne,
    \item źródło danych -- dane zebrane przez przyrządy pomiarowe znacząco różnią się
          od danych zebranych w ramach ankiety.
\end{itemize}
\subsection{Perspektywy na przyszłość}

Aktualne trendy wskazują, że metody wypełniania zbiorów danych będą zyskiwały na znaczeniu.
Wynika to z rosnącego znaczenia zbierania i analizowania danych. Coraz więcej branż zaczyna opierać swoje działania
na analizie danych z różnych źródeł.
Tworzone, przechowywane i analizowane są ogromne zbiory danych o różnym przeznaczeniu, tak zwane Big Data. \cite{bigata}
Uruchamiane są przedsięwzięcia Open Government Data, polegające na udostępnianiu przez organy administracji publicznej
swoich zbiorów danych. \cite{ogd} \cite{ogdpl}

Większa ilość danych oznacza większą ilość braków. Większa ilość braków wymusza tworzenie nowych,
dokładniejszych i szybszych metod ich wypełniania. Przewidywane kierunki rozwoju algorytmów wypełniania obejmują: \cite{future}

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item nowe, bardziej zaawansowane metody wypełniania, tworzone z myślą o konkretnych typach danych,
    \item zwiększanie integracji z innymi narzędziami do analizy danych,
    \item zwiększanie znaczenia uczenia maszynowego,
    \item więcej metod weryfikujących poprawność wypełnienia.
\end{itemize}

\clearpage
\section{Omówienie narzędzi i danych}

\subsection{Python}

Python to interpretowany język wysokiego poziomu o ogólnym zastosowaniu.
Stworzony został w roku 1991 przez Guido van Rossuma.
Został zaprojektowany jako następca języka ABC \cite{abc}, posiadający obsługę wyjątków i działający na systemie operacyjnym Amoeba. \cite{python2}
Python jest wciąż wciąż rozwijany, najnowsza stabilna wersja to 3.11.2.

Python znany jest ze swojej prostej do zrozumienia składni,
czytelnego kodu, wsparcia różnych paradygmatów programowania (obiektowego, imperatywnego, funkcyjnego),
dużej biblioteki standardowej i bardzo szerokiego wyboru dodatkowych bibliotek. \cite{python3}

Do słabszych stron języka zaliczyć można słabą wydajność pod względem prędkości działania i wykorzystania pamięci
bądź problemy z kompatybilnością kodu napisanego w różnych wersjach lub implementacjach Pythona. \cite{python3}

\subsection{Visual Studio Code}

Zintegrowane środowisko programistyczne, w skrócie IDE (od ang. integrated development enviroment)
to aplikacja dostarczająca komplet narzędzi potrzebnych programistom w celu tworzenia aplikacji.
Zazwyczaj IDE składa się z minimum: edytora kodu, kompilatora i debuggera.
Niektóre środowiska oferują dodatkowe funkcje takie jak automatyczne uzupełnianie kodu, podświetlanie składni,
automatyczne formatowanie kodu, narządzia do analizy kodu czy narządzia kontroli wersji.
Dobór odpowiedniego środowiska programowania jest istotny, ponieważ może znacznie zwiększyć produktywność programisty. \cite{ide}

Jako środowisko programowania wykorzystane do przygotowania programu do testowania algorytmów
wybrano Microsoft Visual Studio Code. \cite{vsc}
Jest to darmowy IDE o otwartym kodzie źródłowym. Stworzony został przez firmę Microsoft w roku 2015.
Zaprojektowany został z myślą tworzenia aplikacji webowych i chmurowych z wykorzystaniem wielu języków.
Ze wzglądu na otwartość kodu, dostępne jest wiele rozszerzeń do programu,
które znacznie ułatwiają tworzenie także projektów o dużym stopniu złożoności. \cite{vsc2}

\subsection{GitHub}

W celu umożliwienia pracy nad programem z wielu urządzeń oraz dla zachowania pełnej historii
tworzenia programu wykorzystano integrację Visual Studio Code z repozytorium GitHub, tworząc
prywatne repozytorium kodu. \cite{github}

GitHub to platforma umożliwiająca programistom współpracę nad projektami, udostępnianie kodu i
udzielanie się w projektach o otwartym kodzie źródłowym. Jest to największa tego typu platforma na świecie. \cite{github2}

Jednym z najważniejszych elementów GitHub jest Git. Jest to rozproszony system kontroli wersji,
przygotowany przez Linusa Torvaldsa i wydany w roku 2005. Oryginalnie służył do pomocy przy rozwoju jądra Linux.
Pozwala na śledzenie zmian w kodzie oraz pracę nad wieloma gałęziami projektu w tym samym czasie. \cite{git}

\subsection{Biblioteki}
\subsubsection{Pandas}

Pandas to popularna biblioteka służąca manipulacji i analizy danych w Pythonie.
Stworzona została w roku 2008 przez Wesa McKinney'a i jest stale rozwijana przez grupę deweloperów.
Nazwa Pandas pochodzi od "Python data analysis". \cite{pandas}

Najważniejsze zalety Pandas to:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item wsparcie dla wielu formatów danych, w tym CSV, Excel, SQL i inne,
    \item duża szybkość przeprowadzania operacji na danych,
    \item obsługa brakujących wartości w danych,
    \item łatwa integracja z innymi popularnymi bibliotekami,
    \item bardzo rozbudowana dokumentacja.
\end{itemize}

Pandas wykorzystuje dwie główne struktury danych: Series i DataFrame.
Ta pierwsza to jednowymiarowa tablica wartości posiadająca indeksy każdego elementu,
z kolei druga to dwuwymiarowa tablica wartości z indeksami zarówno rzędów jak i kolumn.
Obydwie struktury mogą przechowywać dowolne typy danych. \cite{pandas2}

\subsubsection{NumPy}

NumPy to biblioteka dla Pythona wykorzystywana do pracy na obiektach będących wielowymiarowymi tablicami
oraz udostęniajaca szereg narzędzi do obliczeń naukowych. Została stworzona w roku 2005 przez Travisa Oliphanta
jako następca bibliotek Numeric \cite{numeric} i Numarray \cite{numarray}. Biblioteka jest wciąż rozwijana przez grupę programistów.
NumPy jest szeroko wykorzystywana do przeprowadzania obliczeń naukowych ze względu na szereg zalet: \cite{numpy2}\cite{numpy3}

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item wspiera wielowymiarowe tabele, zarówno o homogenicznych jak i heterogenicznych typach danych,
    \item oferuje dużą ilość funkcji matematycznych, generatorów liczb pseudolosowych, transformat i innych narzędzi
          przydatnych w zastosowaniach naukowych,
    \item łatwo integruje się z innymi bibliotekami,
    \item posiada bardzo rozbudowaną dokumentację.
\end{itemize}

Do wad zaliczają się stosunkowo niska wydajność i problemy z obsługą niektórych typów danych i brakujących wartości. \cite{numpy3}

\subsubsection{SciKit-learn}

SciKit-learn to biblioteka zawierająca narzędzia związane z uczeniem maszynowym dla Pythona.
Jest częścią większego zestawu narzędzi SciKit,
zawierającego biblioteki oferujące szeroki wachlarz narzędzi do analizy danych.
Początkowo stworzony przez Davida Cournapeau jako projekt w ramach ``Google Summer of Code'' w roku 2007,
został później przepisany i rozwinięty przez Francuski Instytut Badań w Dziedzinie Informatyki i Automatyki (INRIA)
i udostępniony publicznie w roku 2010.\cite{inria}
SciKit-learn przestrzega zasad projektowania API dla oprogramowania uczenia maszynowego,
które obejmują między innymi spójność, rozsądne domyślne ustawienia i dokumentację. \cite{scikit}

\subsubsection{EasyGUI}

EasyGUI to biblioteka Pythona służaca do implementacji prostego interfejsu graficznego.
Został stworzony przez Stephena Ferga i udostępniony w roku 2004. Oparty jest na bibliotece Tkinter \cite{tkinter}.
Główną zaletą EasyGUI jest jego prosta składnia, pozwalajaca na tworzenie nieskomplikowanych aplikacji bez
konieczności uczenia się stosowania bardziej zaawansowanych bibliotek.
Osiągnięte to zostało przez zastosowanie predefiniowanych okien spełniających najczęściej wykorzystywane role,
takie jak okna wyboru, wyświetlanie wiadomości, wpisywanie tekstu i inne.
Niestety zaprzestano dalszego rozwoju biblioteki, przez co nie można spodziewać się dodania nowych funkcji
czy poprawy działania istniejących. \cite{easygui}

\subsection{Źródła danych}

\subsubsection{Użyte repozytoria danych}

Aby wyniki badań niosły ze sobą odpowiednią wartość merytoryczną,
potrzebne są odpowiednie zbiory danych na których zostaną przeprowadzone testy.
W celu znalezienia odpowiednich zbiorów danych, przyjęto następujące założenia:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item zbiór danych musi być wystarczająco duży,
    \item zbiór danych musi zawierać odpowiedniż ilość atrybutów aby modele decyzyjne miały
          do dyspozycji wystarczającą ilość danych uczących,
    \item atrybuty powinny zawierać różnorodne typy danych w celu przetestowania wypełniania zarówno danych
          liczbowych (całkowitych i zmiennoprzecinkowych) jak i kategorycznych,
    \item zbiór danych nie może mieć pustych wartości.
\end{itemize}

Do wyszukania odpowiednich zbiorów danych wykorzystano narzędzie Google Dataset Search. \cite{googlesearch}\cite{googlesearch2}
Z jego pomocą wybrano 2 zbiory danych z róźnych dziedzin.
Po uprzedniej ich obróbce zostały wykorzystane do przeprowadzenia testów algorytów wypełniania.
\subsubsection{Adult Data Set}

Piwerwszy zbiór danych "Adult Data Set" zawiera dane ze spisu ludności przeprowadzonego w roku 1994 w Stanach Zjednoczonych.
Jest szeroko wykorzystywany do testowania uczenia maszynowego.
Zawiera ponad 30000 rekordów i 15 atrybutów. \cite{adult} Opis atrybutów:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item age: wiek spisanej osoby, liczba całkowita,
    \item workclass: rodzaj zatrudnienia, dane kategoryczne, 8 możliwych wartości,
    \item fnlwgt: jaka proporcja populacji ma identyczny zestaw pozostałych wartości, liczba całkowita,
    \item education: osiągnięty poziom edukacji, dane kategoryczne, 16 możliwych wartości,
    \item education-num: osiągnięty poziom edukacji zakodowany jako liczba całkowita,
    \item martial-status: status matrymonialny, dane kategoryczne, 7 możliwych wartości,
    \item occupation: zawód, dane kategoryczne, 14 możliwych wartości,
    \item relationship: rola w związku, dane kategoryczne, 6 możliwych wartości,
    \item race: klasyfikacja rasowa, dane kategoryczne, 5 możliwych wartości,
    \item sex: płeć, dane kategoryczne, 2 możliwe wartości,
    \item capital-gain: zysk kapitału w zwiazku z inwestycjami, liczba całkowita,
    \item capital-gain: strata kapitału w zwiazku z inwestycjami, liczba całkowita,
    \item hours-per-week: ilość godzin pracujących w tygodniu, liczba całkowita,
    \item native-country: kraj pochodzenia, dane kategoryczne, 41 możliwych wartości,
    \item attribute: czy osoba zarabia powyżej czy poniżej 50000\$ rocznie.
\end{itemize}

Ten zbiór danych został wybrany ze względu na występowanie zarówno atrybutów liczbowych jak i kategorycznych,
zadowalajacą ilość rekordów oraz atrybutów.
został wybrany do celu przetestowanie skuteczności działania algorytmów do wypełniania brakujących miejsc
w zbiorach danych z brakami w danych o różnych typach.
Nie wymaga dodatkowej obróbki przed rozpoczęciem testów.
\subsubsection{Stock Exchange Data}

Drugi zbiór danych "Stock Exchange Data" zawiera informacje o cenach akcji na giełdach w różnych krajach w latach 1965-2021.
Dane zostały zebrane z Yahoo Finance, posiadającego dane o giełdzie z wielu lat w wielu krajach.
Posiada ponad 100000 rekordów i 9 atrybutów. \cite{stock} Opis atrybutów:
\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item Index: symbol wskazujacy z jakiej giełdy pochodzą dane, dane kategoryczne, 5 możliwych wartości,
    \item Date: data obserwacji, dane kategoryczne,
    \item Open: cena akcji podczas otwarcia, liczba wymierna,
    \item High: najwyższa cena w ciągu dnia, liczba wymierna,
    \item Low: najniższa cena w ciągu dnia, liczba wymierna,
    \item Close: cena akcji w momencie zamknięcia, liczba wymierna,
    \item Adj Close: cena akcji w momencie zamknięcia skorygowana o podziały jak i dywidendy, liczba wymierna,
    \item Volume: liczba akcji będących przedmiotem obrotu w ciągu dnia sesyjnego, liczba całkowita,
    \item CloseUSD: cana akcji w momencie zamknięcia wyrażona w dolarach amerykańskich.
\end{itemize}
Ten zbiór danych został wybrany ze względu na bardzo popularną kategorię danych, to jest dane finansowe.
Ma na celu przetestowanie skuteczności działania algorytmów w przypadku danych numerycznych,
w szególności liczb wymiernych (typu float).
W celu lepszego przygotowania do testów zakodowano kolumnę Data z wykorzystaniem label encoding,
to jest zamiany danych na postać numeryczną.
Usunięto też rekordy posiadające wartość "0" w kolumnie "Volume".
Ich duża liczba (ponad 30\%) mogłaby negatywnie wpłynąć na uczenie modeli decyzyjnych.
W wyniku tego zmniejszono liczbę rekordów do ponad 62000.


\clearpage
\section{Implementacja i testy}
\subsection{Opis przygotowanego programu}
\subsubsection{Założenia i realizacja}
Założono, że program ma realizować 3 zadania:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Przygotować dane do wypełniania poprzez sztuczne utworzenie brakujacych wartości.
    \item Wypełnić brakujące wartości z wykorzystaniem wybranych algorytmów.
    \item Ocenić skuteczność wypełniania w celu porównania algorytmów.
\end{enumerate}

Poszczególne zadania zrealizowano jako osobne moduły.

\vspace{5mm}
Przyjęto też następujące założenia:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Wykorzystanym językiem ma być Python.
    \item Program ma być napisany zgodnie z paradygmatem programowania obiektowego.
    \item Poszczególne klasy mają być zawarte w osobnych plikach.
    \item Interakcja z programem ma opierać się o prosty interfejs graficzny.
    \item Dostęp do wszystkich modułów programu ma być zapewniony z jednego miejsca.
    \item Pliki wygenerowane przez jeden moduł mają być przygotowane w sposób umożliwiający
          wykorzystanie ich przez kolejny. Oprócz odpowiedniego formatowania wewnątrz pliku,
          oznacza to przyjęcie konwencji nazewnictwa plików opartej o prefiksy i sufiksy.
\end{enumerate}

Program składa się z następujacych plików:

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item mgr\_main.py: główny plik nie zawierający żadnej klasy, odpowiadający za wybór modułu do uruchomienia,
          i uruchomienie odpowiedniego modułu po wybraniu,
    \item mgr\_nan\_gen.py: plik zawierajacy klasę NanGen, odpowiadającą za realizację modułu przygotowujacego plik,
    \item mgr\_fill.py: plik zawierający klasę Fill, odpowiadającą za realizację modułu wypełniajacego brakuące dane,
    \item mgr\_data.py: plik zawierający klasę Data,
          odpowiadającą za wybranie pliku do wypełnienia i przygotowanie do do dalszej obróbki, oraz klasę PrepareData,
          odpowiadającą za przygotowanie danych do przekazania silnikowi uczenia maszynowego celem wypełnienia
          oraz późniejszemu przywróceniu danym ich pierwotnego wyglądu
    \item mgr\_di.py: plik zawierjący klasę DownImpu,
          odpowiadającą za przygotowanie danych dla algorytmu trzeciego.
    \item mgr\_temp\_fill: plik zawierający klasę TempFill, odpowiadającą za tymczasowe wypełnianie brakujących miejsc,
          potrzebne podczas przygotowywania danych dla algorytmu Prostego
    \item mgr\_acc: plik zawierający klasę AccuracyTester, odpowiadającą za obliczanie skuteczności wypełniania danych.
\end{itemize}

Wykorzystując narzędzie auto-py-to-exe, utworzono plik mgr\_suite.exe,
pozwalajacy uruchomić program bez konieczności instalowania interpretera Python i potrzebnych bibliotek. \cite{autopy}
\subsubsection{Działanie programu}
Poniżej zaprezentowano działanie programu na przykładzie pliku data\_stock.csv.
Zostanie on najpierw przygotowany do testów,
następnie brakujace dane zostaną wypełnione z wykorzystaniem jednego z algorytmów,
po czym zostanie obliczona dokładność tego wypełnienia.

\vspace{5mm}
% Uruchomienie
Po uruchomieniu mgr\_suite.exe wyświetlone zostaje okno służące do wyboru modułu, pokazane na rysunku \ref{Fig:main}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/01.jpg}
    \caption{Główne okno programu, pozwalajace na wybór modułu do uruchomienia}
    \label{Fig:main}
\end{figure}
\FloatBarrier
% Przygotowanie danych

Pierwszy moduł odpowiada za przygotowanie danych do wypełniania poprzez usunięcie losowych wartości ze zbioru danych.
Pierwszym krokiem jest wybranie pliku który ma zostać przygotowany
z użyciem okna pokazanego na rysunku \ref{Fig:gen_file}.
Lista plików generowana jest na podstawie plików znajdujących się
w tym samym folderze co uruchamiany program spełniających założony format nazwy.
Założono, że pliki które nadają się do wypełnienia mają być zapisane w formacie CSV,
natomiast nazwa zaczynać się ma od prefiksu ``data\_'' i nie posiadać żadnych sufiksów.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/02.jpg}
    \caption{Okno wyboru pliku do przygotowania}
    \label{Fig:gen_file}
\end{figure}
\FloatBarrier

Następnie wybrane z listy zostają kolumny w których maja zostać usunięte dane.
Wyboru dokonuje się z użyciem okna pokazanego na rysunku \ref{Fig:gen_col}.
Kolumny do wyboru wyekstrahowane są bezpośrednio z załadowanego wcześniej pliku.
Wybrać można dowolną kombinację, lecz zalecane jest poniżej 50\%.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/03.jpg}
    \caption{Okno wyboru kolumn}
    \label{Fig:gen_col}
\end{figure}
\FloatBarrier

W wybranych kolumnach zostaje usunięte od 5\%
do 15\% wartości - dla każdej kolumny faktyczna wartość jest losowana.
Dodatkowo stworzony zostaje plik przechowujęcy informacje które wartości zostały usunięte.
Ta informacja zostaje później wykorzystana do oceny skuteczności wypełnienia zbioru danych.
Po zakończeniu usuwania wartości wyświetlone zostaje okno z podsumowaniem jak na rysunku \ref{Fig:gen_end}.
Nazwa utworzonego pliku z gotowymi danymi tworzona jest
poprzez dodanie sufiksu ``\_holes\_X'' do nazwy oryginalnego pliku, gdzie X to kolejna liczba naturalna.
Umożliwia to tworzenie plików z danymi usuniętymi z różnych zestawów kolumn bez konieczności ręcznej zmiany ich nazw.
Nazwa pliku z informacją które dane zostały usunięte tworzona jest
przez dodanie sufiksu ``\_journal'' do nazwy oryginalnego pliku.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/04.jpg}
    \caption{Okno z podsumowaniem}
    \label{Fig:gen_end}
\end{figure}
\FloatBarrier

% Wypełnianie brakujących wartości

Drugi moduł służy do wypełniania brakujacych wartości w zbiorze danych z użyciem wybranego algorytmu.

Najpierw należy wskazać plik który ma zostać wypełniony z użyciem okna wyboru pokazanego na rysunku \ref{Fig:fill_file}.
Tak jak wcześniej, lista tworzona jest na podstawie plików w folderze i przyjętej konwencji nazewnictwa plików.
Wyświetlane są wyłącznie pliki posiadające sufiks ``\_holes\_X'' w nazwie, bez kolejnych sufiksów.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/05.jpg}
    \caption{Okno wyboru pliku do wypełnienia}
    \label{Fig:fill_file}
\end{figure}
\FloatBarrier

Następnie z użyciem okna jak na rysunku \ref{Fig:fill_alg}
wybrany zostaje algorytm który ma zostać wykorzystany do wypełniania brakujących wartości.
Wyświetlona zostaje też nazwa wybranego wcześniej pliku w celu uniknięcia błędu wybrania niewłaściwego pliku.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/06.jpg}
    \caption{Okno wyboru algorytmu}
    \label{Fig:fill_alg}
\end{figure}
\FloatBarrier

Puste miejsca zostają wypełnione z wykorzystaniem wybranego algorytmu.
Dokładny sposób działania algorytmów zostanie opisany w kolejnych rozdziałach.
Po zakończeniu wypełniania wyświetlone zostaje podsumowanie jak na rysunku \ref{Fig:fill_end}.
Nazwa pliku wynikowego tworzona jest poprzez dodanie sufixu ``\_filled\_Y'', gdzie Y to nazwa wybranego algorytmu.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/07.jpg}
    \caption{Okno z podsumowaniem wypełniania}
    \label{Fig:fill_end}
\end{figure}
\FloatBarrier

% Sprawdzenie skuteczności wypełniania

Ostatni moduł odpowiada za wygenerowanie danych,
które można wykorzystać do oceny skuteczności wypełniania brakujących wartości.
Jako wystarczające uznano procent skuteczności wypełniania dla danych kategorycznych i liczb całkowitych
oraz średnie odchylenie bezwzględne dla wszystkich danych liczbowych.
Obie wartości są obliczane dla poszczególnych wypełnionych kolumn.

Jak w przypadku poprzednich modułów, zacząć należy od wyboru pliku który ma zostać poddany analizie.
Wyboru dokonuje się z użyciem okna pokazanego na rysunku \ref{Fig:acc_file}.
Wyświetlane są tylko pliki zawierające słowo ``filled'' w nazwie, ponieważ takie pliki
posiadają wartości wypełnione za pomocą któregoś algorytmu z użyciem odpowiedniego modułu.

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/08.jpg}
    \caption{Okno wyboru pliku do analizy}
    \label{Fig:acc_file}
\end{figure}
\FloatBarrier

Z użyciem wybranego pliku, oryginalnego pliku z danymi przed usunięciem losowych danych
oraz pliku z informacją które dane zostały usunięte a następnie wypełnione,
przeprowadzane jest obliczanie skuteczności wypełniania danych.

Obliczenie procentowej skuteczności wypełnienia przebiega następująco:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Sprawdzenie ilości wypełnianych wartości w danej kolumnie.
    \item Zsumowanie ilości poprawnie wypełnionych danych w kolumnie poprzez porównanie wartości o współrzędnych
          zapisanych w pliku tworzonym podczas przygotowywania danych.
    \item Zastosować wzór \ref{Eq:acc}:
          \begin{equation}
              ACC=\frac{m}{n}\times100\%
              \label{Eq:acc}
          \end{equation}
          gdzie: $ACC$ -- procentowa skuteczność wypełnienia kolumny,
          $m$ -- ilość poprawnie wypełnionych wartości,
          $n$ -- ilość wypełnionych wartości.
\end{enumerate}

Aby obliczyć średnie odchylenie bezwzględne należy zastosować wzór \ref{Eq:aad}:

\begin{equation}
    AAD=\frac{\sum_{i=1}^{n}|x_i - \hat{x_i}|}{n}
    \label{Eq:aad}
\end{equation}

gdzie: $AAD$ -- średnie odchylenie bezwzględne dla danej kolumny,
$n$ -- ilość wypełnionych wartości w kolumnie,
$x_i$ -- wartość wypełnionego $i$-tego elementu kolumny,
$\hat{x_i}$ -- oryginalna wartość $i$-tego elementu kolumny.

Po zakończeniu obliczeń, wyświetlane jest podsumowanie jak na rysunku \ref{Fig:acc_end},
a wynik obliczeń zapisywany jest w dwóch plikach

\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item wyniki obliczania procentowej skuteczności jest zapisywany w pliku o nazwie
          tworzonej przez dodanie do nazwy analizowanego pliku sufiksu "\_aad",
    \item wyniki obliczania średniego odchylenia bezwzględnego jest zapisywany w pliku o nazwie
          tworzonej przez dodanie do nazwy analizowanego pliku sufiksu "\_acc".
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{img/09.jpg}
    \caption{Okno z podsumowaniem}
    \label{Fig:acc_end}
\end{figure}
\FloatBarrier

\subsection{Opis implementacji algorytmów}

Implementowane algorytmy opierają się o kolejne rozwinięcia idei zaprezentowanej w \cite{wybZag}.
Polega ona na sformułowaniu problemu wypełniania problemu wypełniania brakujących wartości jako problemu decyzyjnego.
Wynikają z tego następujące założenia:
\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item kolumny wypełniane są pojedyńczo,
    \item samo wypełnianie przeprowadzane jest przez system decyzyjny,
    \item algorytm ma za zadanie wybrać kolejność wypełniania kolumn oraz
          określić jakie kolumny będą zawarte w zbiorze danych uczących systemu decyzyjnego.
\end{itemize}

Działanie poszczególnych algorytmów zostanie zaprezentowane na przykładowej tabeli \ref{tab:base}
przedstawiającej zbiór danych:
\begin{table}[ht]
    \caption{Tabela wyjściowa}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
           & A & B & C & D & E & F & G & H & I & J & K & L & M & N \\ \hline
        1  & * & * & x & * & * & * & x & * & * & * & x & * & * & * \\ \hline
        2  & x & * & * & * & * & * & * & * & * & * & * & x & * & * \\ \hline
        3  & * & * & * & * & x & * & * & * & * & * & * & x & * & * \\ \hline
        4  & x & * & x & * & x & * & x & x & * & * & x & x & * & * \\ \hline
        5  & * & * & * & * & x & * & * & x & x & * & * & * & * & * \\ \hline
        6  & * & * & * & * & x & * & x & x & * & * & * & * & * & * \\ \hline
        7  & * & * & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
        8  & * & * & * & * & * & * & * & x & * & * & x & * & x & * \\ \hline
        9  & * & * & * & * & x & * & * & * & x & * & * & * & x & * \\ \hline
        10 & * & * & * & * & * & * & x & * & x & * & * & * & * & * \\ \hline
        11 & * & x & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
    \end{tabular}
    \label{tab:base}
\end{table}
\FloatBarrier
gdzie: $*$ -- istniejąca wartość, $x$ -- brakująca wartość.

\subsubsection{Algorytm pierwszy}

Procedura dla algorytmu pierwszego wygląda następująco:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Tworzony jest zbiór kolumn z brakującymi wartościami $X$.
          Dla przykładowej tabeli zbiór będzie wyglądał następująco:

          $X=\{A,B,C,E,G,H,I,K,L,M\}$.
    \item Kolumny w zbiorze $X$ są następnie sortowane od kolumn zawierających
          najmniejszą ilość brakujących wartości do zawierających ich najwięcej, dając ciąg $\eta$.
          W przypadku kolumn o takiej samej ilości brakujących danych kolejność nie ma znaczenia.
          Dla przykładowej tabeli zbiór ten będzie wyglądał następująco:

          $\eta=(B,M,C,A,L,K,I,H,G,E)$.
    \item Pierwszy element w ciągu $\eta$ zostaje wybrany jako kolumna która zostanie wypełniona.
          W przykładzie będzie to element $B$.
    \item Tabela zostaje rozdzielona na dwie: w jednej znajdują się rekordy
          w których w kolumnie wybranej do wypełnienia znajdują się dane,
          a w drugiej rekordy w których w wybranej tabeli danych brakuje.
          Dla przykładowej tabeli będzie to wyglądało następująco,
          gdzie tabela \ref{tab:1_full} przedstawia tabelę z danymi w wybranej kolumnie,
          natomiast tabela \ref{tab:1_nan} przedstawia tabelę z brakiem danych w wybranej kolumnie.

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej, zawierająca wyłacznie rekordy z danymi w rozważanej kolumnie}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & A & B & C & D & E & F & G & H & I & J & K & L & M & N \\ \hline
                  1  & * & * & x & * & * & * & x & * & * & * & x & * & * & * \\ \hline
                  2  & x & * & * & * & * & * & * & * & * & * & * & x & * & * \\ \hline
                  3  & * & * & * & * & x & * & * & * & * & * & * & x & * & * \\ \hline
                  4  & x & * & x & * & x & * & x & x & * & * & x & x & * & * \\ \hline
                  5  & * & * & * & * & x & * & * & x & x & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & x & * & x & x & * & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * & * & * & x & * & * & x & * & x & * \\ \hline
                  9  & * & * & * & * & x & * & * & * & x & * & * & * & x & * \\ \hline
                  10 & * & * & * & * & * & * & x & * & x & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:1_full}
          \end{table}
          \FloatBarrier

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej,
                  zawierająca wyłacznie rekordy z brakiem danych w rozważanej kolumnie}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & A & B & C & D & E & F & G & H & I & J & K & L & M & N \\ \hline
                  11 & * & x & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:1_nan}
          \end{table}
          \FloatBarrier

    \item Pierwsza z tabel - w przykładzie tabela \ref{tab:1_full} - posłuży do trenowania modelu uczenia maszynowego.
          Wypełniana kolumna służy jako cel, a pozostałe jako dane uczące.
    \item Następnie nauczony model zostaje wykorzystany do wypełnienia brakujących wartości w drugiej tabeli,
          w przykładzie tabeli \ref{tab:1_nan}.
    \item Na koniec tabele są łączone w jedną co w przykładzie poskutkuje tabelą \ref{tab:1_end},
          a algorytm jest powtarzany aż do wypełnienia wszystkich brakujących wartości.

          \begin{table}[ht]
              \caption{Tabela prezentująca wygląd danych po pojedynczym przejściu głównej pętli algorytmu}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & A & B & C & D & E & F & G & H & I & J & K & L & M & N \\ \hline
                  1  & * & * & x & * & * & * & x & * & * & * & x & * & * & * \\ \hline
                  2  & x & * & * & * & * & * & * & * & * & * & * & x & * & * \\ \hline
                  3  & * & * & * & * & x & * & * & * & * & * & * & x & * & * \\ \hline
                  4  & x & * & x & * & x & * & x & x & * & * & x & x & * & * \\ \hline
                  5  & * & * & * & * & x & * & * & x & x & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & x & * & x & x & * & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * & * & * & x & * & * & x & * & x & * \\ \hline
                  9  & * & * & * & * & x & * & * & * & x & * & * & * & x & * \\ \hline
                  10 & * & * & * & * & * & * & x & * & x & * & * & * & * & * \\ \hline
                  11 & * & * & * & * & x & * & * & * & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:1_end}
          \end{table}
          \FloatBarrier
\end{enumerate}

\subsubsection{Algorytm drugi}

Algorytm drugi jest rozwinięciem pierwszego. Róźni się sposobem wyboru kolumn mających pełnić rolę
danych uczących. Eliminuje on z tego zbioru kolumny które również posiadają brakujące dane.
Oznacza to, że kolumny wypełniane w pierwszej kolejności wypełniane są z użyciem silnika uczenia maszynowego
uczącego się na mniejszej ilości danych, lecz lepszej jakości.

Procedura dla algorytmu drugiego wygląda następująco:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Tworzony jest zbiór kolumn z brakującymi wartościami $X$.
          Dla przykładowej tabeli zbiór będzie wyglądał następująco:

          $X=\{A,B,C,E,G,H,I,K,L,M\}$.
    \item Kolumny w zbiorze $X$ są następnie sortowane od kolumn zawierających
          najmniejszą ilość brakujących wartości do zawierających ich najwięcej, dając ciąg $\eta$.
          W przypadku kolumn o takiej samej ilości brakujących danych kolejność nie ma znaczenia.
          Dla przykładowej tabeli zbiór ten będzie wyglądał następująco:

          $\eta=(B,M,C,A,L,K,I,H,G,E)$.
    \item Pierwszy element w ciągu $\eta$ zostaje wybrany jako kolumna która zostanie wypełniona.
          W przykładzie będzie to element $B$.
    \item Tabela zostaje podzielona na dwie. W jednej znajdują się kolumny z pustymi wartościami,
          oprócz tej która ma zostać wypełniona.
          W drugiej znajdują się kolumny pełne oraz ta wyznaczona do wypełnienia.
          Tabele \ref{tab:2_nan} i \ref{tab:2_full} przedstawiają rodzielenie tabeli dla rozważanego przykładu:

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej, zawierająca tylko kolumny z brakującymi danymi,
                  z wyjątkiem wyznaczonej do wypełnienia}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & A & C & E & G & H & I & K & L & M \\ \hline
                  1  & * & x & * & x & * & * & x & * & * \\ \hline
                  2  & x & * & * & * & * & * & * & x & * \\ \hline
                  3  & * & * & x & * & * & * & * & x & * \\ \hline
                  4  & x & x & x & x & x & * & x & x & * \\ \hline
                  5  & * & * & x & * & x & x & * & * & * \\ \hline
                  6  & * & * & x & x & x & * & * & * & * \\ \hline
                  7  & * & * & x & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & x & * & x & * & x \\ \hline
                  9  & * & * & x & * & * & x & * & * & x \\ \hline
                  10 & * & * & * & x & * & x & * & * & * \\ \hline
                  11 & * & * & x & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_nan}
          \end{table}
          \FloatBarrier

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej,
                  zawierająca tylko kolumny bez brakujących danych i kolumnę wyznaczoną do wypełnienia}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N \\ \hline
                  1  & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * \\ \hline
                  9  & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * \\ \hline
                  11 & x & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_full}
          \end{table}
          \FloatBarrier

    \item Tabela z kolumną do wypełnienia znowu zostaje rozdzielona. W jednej znajdują się rekordy
          w których w kolumnie wybranej do wypełnienia znajdują się dane,
          a w drugiej rekordy w których w wybranej tabeli danych brakuje.
          Dla przykładowej tabeli będzie to wyglądało następująco,
          gdzie tabela \ref{tab:2_full_full} przedstawia tabelę z danymi w wybranej kolumnie,
          natomiast tabela \ref{tab:2_full_nan} przedstawia tabelę z brakiem danych w wybranej kolumnie.

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej,
                  zawierająca tylko kolumny bez brakujących danych i kolumnę wyznaczoną do wypełnienia}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N \\ \hline
                  1  & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * \\ \hline
                  9  & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_full_full}
          \end{table}
          \FloatBarrier

          \begin{table}[ht]
              \caption{Tabela wydzielona z oryginalnej,
                  zawierająca tylko kolumny bez brakujących danych i kolumnę wyznaczoną do wypełnienia}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N \\ \hline
                  11 & x & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_full_nan}
          \end{table}
          \FloatBarrier

    \item Pierwsza z tabel - w przykładzie tabela \ref{tab:2_full_full} - posłuży do trenowania modelu uczenia maszynowego.
          Wypełniana kolumna służy jako cel, a pozostałe jako dane uczące.
    \item Następnie nauczony model zostaje wykorzystany do wypełnienia brakujących wartości w drugiej tabeli,
          w przykładzie tabeli \ref{tab:2_full_nan}.
    \item Następnie tabele są łączone spowrotem w jedną, przywracając oryginalne rozmiary. W pierwszej kolejności
          łączone są ze sobą tabele które brały udział w uczeniu i wypełnianiu.
          W przykładzie będą to tabele \ref{tab:2_full_full} i \ref{tab:2_full_nan} tworząc \ref{tab:2_full_end}.

          \begin{table}[ht]
              \caption{Tabela wynikająca z połączenia tabel biorących udział w nauczaniu i wypełnianiu}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N \\ \hline
                  1  & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * \\ \hline
                  9  & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * \\ \hline
                  11 & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_full_end}
          \end{table}
          \FloatBarrier

    \item Na koniec dołączana jest wcześniej utworzona tabela zawierająca wyłącznie kolumny z brakującymi wartościami.
          W przykładzie oznacza to łączenie tabel \ref{tab:2_full_end} i \ref{tab:2_nan}, uzyskując tabelę \ref{tab:2_end}.

          \begin{table}[ht]
              \caption{Tabela prezentująca wygląd danych po pojedynczym przejściu głównej pętli algorytmu}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N & A & C & E & G & H & I & K & L & M \\ \hline
                  1  & * & * & * & * & * & * & x & * & x & * & * & x & * & * \\ \hline
                  2  & * & * & * & * & * & x & * & * & * & * & * & * & x & * \\ \hline
                  3  & * & * & * & * & * & * & * & x & * & * & * & * & x & * \\ \hline
                  4  & * & * & * & * & * & x & x & x & x & x & * & x & x & * \\ \hline
                  5  & * & * & * & * & * & * & * & x & * & x & x & * & * & * \\ \hline
                  6  & * & * & * & * & * & * & * & x & x & x & * & * & * & * \\ \hline
                  7  & * & * & * & * & * & * & * & x & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * & * & * & * & * & x & * & x & * & x \\ \hline
                  9  & * & * & * & * & * & * & * & x & * & * & x & * & * & x \\ \hline
                  10 & * & * & * & * & * & * & * & * & x & * & x & * & * & * \\ \hline
                  11 & * & * & * & * & * & * & * & x & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:2_end}
          \end{table}
          \FloatBarrier

\end{enumerate}
\subsubsection{Algorytm trzeci}

Algorytm trzeci jest kolejnym rozwinięciem drugiego. On również skupia się głównie na zmianie logiki
stojącej za doborem kolumn do wykorzystania w uczeniu silnika.
Dodatkowo zmieniany jest sposób wyboru kolejności w jakiej wypełniane są kolumny.
W przeciwieństwie do poprzedniego algorytmu, kolejność wypełniania kolumn nie jest dyktowana przez samą ilość
brakujących wartości, a ilość brakujących wartości występujących w tych samych rekordach.
Ma to na celu jak najbardziej efektywne uzyskanie informacji mających znaczenie przy wypełnianiu kolejnych kolumn.
Również w tym celu kolumny o najmniejszym wpływie dla wypełniania innych kolumn wypełniane są w sposób prosty,
to znaczy w oparciu o najczęściej występującą wartość lub średnią wartość w kolumnie, zależnie od typu danych.

Procedura dla algorytmu trzeciego wygląda następująco:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Tworzony jest zbiór kolumn z brakującymi wartościami $X$.
          Dla przykładowej tabeli zbiór będzie wyglądał następująco:

          $X=\{A,B,C,E,G,H,I,K,L,M\}$
    \item Ze zbioru $X$ wybierana jest kolumna z największą liczbą brakujących wartości.
          Ta kolumna kolumna jest usuwana ze zbioru $X$ i dodawana do ciągu $\eta$,
          natomiast liczba brakujących wartości w tej kolumnie dodawana jest do ciągu $\delta$.
          W przykładzie jest to kolumna $E$ z 7 brakującymi elementami, a zbiór i ciągi będą wyglądały następująco:

          $X=\{A,B,C,G,H,I,K,L,M\}$, $\eta=(E)$, $\delta=(7)$
    \item Następnie z tak powstałego zbioru $X$ zostaje wybrana kolumna mająca najwięcej wspólnych z poprzednio wybraną
          kolumną brakujacych wartości w rekordach.
          W przypadku gdy liczba wspólnych braków jest równa dla kilku kolumn, można wybrać dowolną z nich.
          Wybrana kolumna usuwana jest ze zbioru $X$ i dodawana do ciągu $\eta$,
          a liczba wspólnych brakujących wartości do ciągu $\delta$.
          W przykładzie jest to $H$, z 3 wspólnymi elementami. Poskutkuje to zbiorem i ciągami:

          $X=\{A,C,G,I,K,L,M\}$, $\eta=(E,H)$, $\delta=(7,3)$
    \item Powyższy krok jest powtarzany aż do wyczerpania elementów zbioru $X$
          W ten sposób tworzone są 2 ciągi. Jeden zawiera kolumny w uzyskanej w ten sposób kolejności, oznaczony jako $\eta$,
          oraz drugi mu odpowiadający oznaczony $\delta$,
          zawierający wartości liczbowe oznaczające liczbę wspólnych z poprzednim elementem brakujacych wartości.
          Te ciągi dla przykładowej tabeli będą wyglądać następująco:

          $\eta=(E,H,G,K,C,L,A,I,M,B)$, $\delta=(7,3,2,2,2,1,2,0,1,0)$
    \item Jeśli ciąg $\delta$ zawiera na końcu wartości zerowe to są one usuwane z tego ciągu,
          a odpowiadające im kolumny zostają wypełnione w sposób prosty i usuwane z ciągu $\eta$.
          W przykładzie poskutkuje to ciągami:

          $\eta=(E,H,G,K,C,L,A,I,M)$, $\delta=(7,3,2,2,2,1,2,0,1)$
    \item Tabela zostaje rozdzielona na podstawie zawartości ciągu $\eta$.
          Jedna tabela wynikowa zawiera kolumny zawarte w tym ciągu, a druga pozostałe, zawierająca wyłącznie kompletne dane.
          Tabele dla przykładu będą wyglądać następująco, gdzie tabela \ref{tab:3_nan} zawiera kolumny z ciągu $\eta$, a tabela \ref{tab:3_full} pozostałe:

          \begin{table}[ht]
              \caption{Tabela zawierająca kolumny zawarte w ciągu $\eta$}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
                  \hline
                     & A & C & E & G & H & I & K & L & M \\ \hline
                  1  & * & x & * & x & * & * & x & * & * \\ \hline
                  2  & x & * & * & * & * & * & * & x & * \\ \hline
                  3  & * & * & x & * & * & * & * & x & * \\ \hline
                  4  & x & x & x & x & x & * & x & x & * \\ \hline
                  5  & * & * & x & * & x & x & * & * & * \\ \hline
                  6  & * & * & x & x & x & * & * & * & * \\ \hline
                  7  & * & * & x & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & x & * & x & * & x \\ \hline
                  9  & * & * & x & * & * & x & * & * & x \\ \hline
                  10 & * & * & * & x & * & x & * & * & * \\ \hline
                  11 & * & * & x & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:3_nan}
          \end{table}
          \FloatBarrier

          \begin{table}[ht]
              \caption{Tabela zawierająca kolumny nie zawarte w ciągu $\eta$}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N \\ \hline
                  1  & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * \\ \hline
                  9  & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * \\ \hline
                  11 & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:3_full}
          \end{table}
          \FloatBarrier



    \item Ze zbioru $\eta$ usuwana jest kolumna będąca ostatnim elementem ciągu
          i dokładana do tabeli zawierającej kompletne dane. Ta kolumna zostanie wypełniana.
          Tabela dzielona jest na dwie, jedną zawierającą rekordy w których wypełniana kolumna zawiera dane,
          i drugą w której wypełniana kolumna danych nie posiada. Pierwsza z nich posłuży jako dane treningowe dla modelu uczenia maszynowego,
          a druga zostanie z jego użyciem wypełniona.
          W rozpatrywanym przypadku przenoszoną kolumną będzie $M$, więc ciągi po jej usunięciu będą wyglądały następująco:

          $\eta=(E,H,G,K,C,L,A,I)$, $\delta=(7,3,2,2,2,1,2,0)$
          Z kolei tabela zawierająca dane treningowe będzie wyglądała jak \ref{tab:3_full_full} , natomist tabela do wypełnienia jak \ref{tab:3_full_nan}.

          \begin{table}[ht]
              \caption{Tabela zawierająca kolumny nie zawarte w ciągu $\eta$}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N & M \\ \hline
                  1  & * & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * & * \\ \hline
                  11 & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:3_full_full}
          \end{table}
          \FloatBarrier

          \begin{table}[ht]
              \caption{Tabela zawierająca kolumny nie zawarte w ciągu $\eta$}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|}
                  \hline
                    & B & D & F & J & N & M \\ \hline
                  8 & * & * & * & * & * & x \\ \hline
                  9 & * & * & * & * & * & x \\ \hline
              \end{tabular}
              \label{tab:3_full_nan}
          \end{table}
          \FloatBarrier

    \item Następnie usyskane po wypełnieniu tabele są łączone w jedną,
          a powyższa procedura polegająca na przenoszeniu i wypełnianiu ostatniej kolumny z ciągu $\eta$
          jest powtarzana aż do jego wyczerpania i tym samym wypełnienia wszystkich kolumn.
          Tabela \ref{tab:3_end} przedstawia tabelę po połączeniu tabel \ref{tab:3_full_full} i \ref{tab:3_full_nan},
          gotową do dodania kolejnej tabeli z ciągu $\eta$

          \begin{table}[ht]
              \caption{Tabela gotowa do powtórzenia procedury dodania i wypełnienia kolumny}
              \centering
              \begin{tabular}{|c|c|c|c|c|c|c|}
                  \hline
                     & B & D & F & J & N & M \\ \hline
                  1  & * & * & * & * & * & * \\ \hline
                  2  & * & * & * & * & * & * \\ \hline
                  3  & * & * & * & * & * & * \\ \hline
                  4  & * & * & * & * & * & * \\ \hline
                  5  & * & * & * & * & * & * \\ \hline
                  6  & * & * & * & * & * & * \\ \hline
                  7  & * & * & * & * & * & * \\ \hline
                  8  & * & * & * & * & * & * \\ \hline
                  9  & * & * & * & * & * & * \\ \hline
                  10 & * & * & * & * & * & * \\ \hline
                  11 & * & * & * & * & * & * \\ \hline
              \end{tabular}
              \label{tab:3_end}
          \end{table}
          \FloatBarrier
\end{enumerate}

\subsection{Napotkane problemy}
\subsection{Testy algorytmów na wybranych źródłach danych}

\subsubsection{Procedura przeprowadzania testu}

Procedura przeprowadzonych testów wyglądała następująco:

\begin{enumerate}[label=\arabic*), leftmargin=1.25cm]
    \item Wybrano zbiory danych do testów: Adult Data Set \cite{adult} i Stock Exchange Data \cite{stock}.
    \item Przygotowano dane w sposób umożliwiający wykorzystanie ich w programie.
          Dane zapisano do plików odpowiednio data\_adult.csv i data\_stock.csv.
    \item Obydwa pliki załadowano do pierwszego modułu programu, przygotowującego dane poprzez wygenerowanie
          brakujacych wartości. Dla pliku data\_adult.csv wybrano kolumny:

          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item age -- dane liczbowe typu int
              \item education -- dane kategoryczne
              \item occupation -- dane kategoryczne
              \item race -- dane kategoryczne
              \item hours-per-week -- dane liczbowe typu int
              \item attribute -- dane kategoryczne
          \end{itemize}

          Te kolumny zostały wybrane aby przetestować skuteczność wypełniania
          zarówno danych liczbowych typu int jak i danych kategorycznych.

          Dla pliku data\_stock.csv wybrano z kolei kolumny:

          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item Open -- dane liczbowe typu float
              \item Low -- dane liczbowe typu float
              \item Volume -- dane liczbowe typu int
              \item CloseUSD -- dane liczbowe typu float
          \end{itemize}

          Te kolumny zostały wybrane aby przetestować skuteczność wypełniania
          zarówno danych liczbowych typu float oraz int.

          W ten sposób wygenerowano gotowe do wypełniania pliki:

          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item data\_adult\_holes\_1.csv
              \item data\_stock\_holes\_1.csv
          \end{itemize}

          Oraz odpowiadające im pliki przechowujące informacje które dane usunięto:

          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item data\_adult\_holes\_1\_journal.csv
              \item data\_stock\_holes\_1\_journal.csv
          \end{itemize}
    \item Następnie dane zostały wypełnione z wykorzystaniem drugiego modułu programu.
          Do wypełniania obu plików wykorzystano wszystkie 3 algorytmy. Uzyskano w ten sposób zestawy wypełnionych plików:

          Wypełnione pliki bazujące na Adult Data Set:
          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item data\_adult\_holes\_1\_filled\_Algorytm 1.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 2.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 3.csv
          \end{itemize}

          Wypełnione pliki bazujące na Stock Exchange Data:
          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item data\_stock\_holes\_1\_filled\_Algorytm 1.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 2.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 3.csv
          \end{itemize}
    \item Każdy z wypełnionych plików został następnie poddany analizie trzecim modułem programu.
          Wygenerował on dla każdego analizowanego pliku informacje o dokładności wypełniania.
          To te pliki są podstawą oceny skuteczności poszczególnych algorytmów.
          Wygenerowane pliki to:
          \begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
              \item data\_adult\_holes\_1\_filled\_Algorytm 1\_aad.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 1\_acc.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 2\_aad.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 2\_acc.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 3\_aad.csv
              \item data\_adult\_holes\_1\_filled\_Algorytm 3\_acc.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 1\_aad.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 1\_acc.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 2\_aad.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 2\_acc.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 3\_aad.csv
              \item data\_stock\_holes\_1\_filled\_Algorytm 3\_acc.csv
          \end{itemize}
\end{enumerate}

\subsubsection{Przedstawienie otrzymanych wyników}

Wyniki testów zebrano i na ich przygotowano tabele \ref{tab:adult_aad}, \ref{tab:adult_acc},
\ref{tab:stock_aad} i \ref{tab:stock_acc} w czytelniejszy sposób przedstawiające wyniki testów, zaokrąglone do 3 miejsc po przecinku:

\begin{table}[ht]
    \caption{Tabela porównująca średnie odchylenie wartości po wypełnianiu danych w zbiorze Adult Data Set}
    \centering
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Kolumna} & \textbf{Algorytm 1} & \textbf{Algorytm 2} & \textbf{Algorytm 3} \\ \hline
        age              & 8,049               & 8,056               & 8,072               \\ \hline
        hours-per-week   & 7,290               & 7,324               & 7,324               \\ \hline
    \end{tabular}
    \label{tab:adult_aad}
\end{table}
\FloatBarrier

\begin{table}[ht]
    \caption{Tabela porównująca procentową skuteczność algorytmów w wypełnianiu danych w zbiorze Adult Data Set}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Kolumna} & \textbf{Algorytm 1} & \textbf{Algorytm 2} & \textbf{Algorytm 3} \\ \hline
        age              & 3,673               & 3,647               & 3,520               \\ \hline
        education        & 100,000             & 100,000             & 100,000             \\ \hline
        occupation       & 26,724              & 24,005              & 26,658              \\ \hline
        race             & 80,434              & 18,481              & 16,822              \\ \hline
        hours-per-week   & 5,495               & 4,974               & 5,258               \\ \hline
        attribute        & 77,089              & 76,989              & 76,194              \\ \hline
    \end{tabular}
    \label{tab:adult_acc}
\end{table}
\FloatBarrier

\begin{table}[ht]
    \caption{Tabela porównująca średnie odchylenie wartości po wypełnianiu danych w zbiorze Stock Exchange Data}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Kolumna} & \textbf{Algorytm 1} & \textbf{Algorytm 2} & \textbf{Algorytm 3} \\ \hline
        Open             & 38,639              & 38,487              & 38,652              \\ \hline
        Low              & 25,429              & 25,381              & 25,382              \\ \hline
        Volume           & 514744105,743       & 517121563,891       & 512315098,820       \\ \hline
        CloseUSD         & 1010,382            & 1036,041            & 1036,041            \\ \hline
    \end{tabular}
    \label{tab:stock_aad}
\end{table}
\FloatBarrier

\begin{table}[ht]
    \caption{Tabela porównująca procentową skuteczność algorytmów w wypełnianiu danych w zbiorze Stock Exchange Data}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Kolumna} & \textbf{Algorytm 1} & \textbf{Algorytm 2} & \textbf{Algorytm 3} \\ \hline
        Open             & 0                   & 0                   & 0                   \\ \hline
        Low              & 0                   & 0                   & 0                   \\ \hline
        Volume           & 0                   & 0                   & 0                   \\ \hline
        CloseUSD         & 0                   & 0                   & 0                   \\ \hline
    \end{tabular}
    \label{tab:stock_acc}
\end{table}
\FloatBarrier

\subsubsection{Interpretacja wyników}

Najważniejszym wnioskiem jest fakt, że różnice w skuteczności między poszczególnymi algorytmami są znikome.
Nie jest to spowodowane charakterystyką danego zbioru danych ani ich typu - we wszystkich przypadkach
różnice w procentowej skuteczności wypełniania nie przekraczają jednego punktu procentowego, a średnie odchylenienie
nie różni się między algorytmami o więcej niż kilka procent.

Jedynym wyjątkiem jest tutaj kolumna ``race'',
której skuteczność dla algorytmu pierwszego po zaokrągleniu wypełniania wyniosła 80\%,
a dla drugiego i trzeciego odpowiednio 18\% i 17\%.
Wynika to z faktu, że w algorytmie drugim i trzecim kolumny wypełniane jako pierwsze
bazują na uczeniu z wykorzystaniem najmniejszej liczby danych.
Jeśli w uczeniu silnika maszynowego mającego wypełnić tą kolumnę brakowało danych z którymi ta jest mocno skorelowana,
słaba skuteczność wypełnienia jest spodziewana.



Kolejną zaobserwowaną właściwością jest duża rozpiętość uzyskanej dokładności wypełniania danych kategorycznych.
Dla kolumny ``education'' jest to aż 100\%, dla ``attribute'' akceptowalne 77\%,
a dla ``occupation'' już tylko okolice 25\%, niezależnie od wykorzystnego algorytmu
(przypadek kolumny ``race'' zostaje tutaj pominięty, ponieważ został już omówiony wcześniej).

Tutaj rolę odgrywa stopień korelacji danych w jednej kolumnie z pozostałymi.
Łatwo pokazać to na przykładzie kolumny ``education''.
Ponieważ kolumna ``education-num'' przechowuje dokładnie te same informacje lecz zakodowane w inny sposób
(numerycznie zamiast tekstowo) odgadnięcie właściwej wartości przez uczenie maszynowe nie stanowi problemu.
Dla pozostałych kolumn silnik nie znalazł porównywalnie mocnych korelacji,
więc skuteczność wypełniania jest niższa.

Ogromne średnie odchylenie dla kolumny ``Volume'' prawdopodobnie wynika z błędu albo w przygotowanym programie albo
wykorzystanym silniku uczenia maszynowego. Po sprawdzeniu uzupełnionych danych, okazało się że wszystkie one są ujemne,
mimo że w oryginalnym zbiorze nie ma żadnych ujemnych wartości - ta kolumna przedstawia liczbę przeprowadzonych
transakcji w ciągu dnia, wartości ujemne są więc niedopuszczalne.

Niska procentowa dokładność wypełniania danych liczbowych jest spodziewanym rezultatem.
Ponieważ tylko idealne dopasowanie jest liczone jako poprawnie wypełniona wartość, nawet najmniejsze odstępstwa
powodują spadek tego wskaźnika. Jest to szczególnie widoczne w przypadku danych typu float, gdzie ten wskaźnik wynosi 0\%.
Dla danych liczbowych znacznie ważniejszym wskaźnikiem jest średnie odchylenie wartości.

Powyższe sugeruje, że przyjęte założenie mówiące, że zmiana logiki stojącej za doborem kolejności wypełniania kolumn
jest niepoprawne i w rzeczywistości ma stosunkowo niskie znaczenie.
Ważny z kolei jest dobór kolumn wykorzystanych do trenowania silnika uczenia maszynowego,
ponieważ może mieć to ogromny wpływ na dokładność, co dosadnie pokazała kolumna ``race''.

\clearpage
\section{Podsumowanie i wnioski końcowe}
Temat niniejszej pracy dyplomowej magisterskiej brzmi ``Implementacja wybranych algorytmów wypełniania brakujących wartości,
dla strumieni dużych zbiorów danych''. Miała ona na celu przedstawić idee stojące za wypełnianiem brakujacych danych,
zaprezentować działanie zaimplementowanych algorytmów oraz je porównać. Do implementacji wykorzystano program
napisany w języku Python z zaimplementowanymi bibliotekami służącymi do obróbki i analizy danych. Testy przeprowadzono
na wybranych odpowiednio dużych zbiorach danych.

Wnioski wyciągnięte z przeprowadzonych testów zaprzeczyły przyjętemu założeniu z myślą o którym przygotowywano
algorytmy do testowania, czyli dużej roli kolejności w jakiej wypełniane są dane. Zwróciły one jednak uwagę na
rolę wykorzystania jak największej ilości danych do trenowania silnika uczenia maszynowego.

Wypełnianie brakujących elementów w dużych zbiorach danych to wciąż rozwijająca się gałęź analizy danych.
Rosnące znaczenie analizy danych dla kolejnych gałęzi przemysłu i nauki wymaga aby dane były tak dobrej jakości
jak to możliwe, a to oznacza również ich kompletność.
Różne dane wymagają różnych sposobów ich wypełniania.
Podczas gdy dla niektórych może być wystarczające proste wstawienie średniej, inne dane będą wymagały zaawansowanych
algorytmów ze zintegrowanymi elementami uczenia maszynowego i automatycznej korekcji błędów.

Autor za własny wkład pracy uważa:
\begin{itemize}[label=-,labelsep=0.4cm, leftmargin=1.25cm]
    \item zebranie informacji dotyczących omawianego tematu,
    \item przygotowanie programu służącego do przeprowadzenia testów,
    \item przygotowanie algorytmów wypełniania brakujących wartości do porównania,
    \item przeprowadzenie testów, analiza uzyskanych wyników i wyciągnięcie wniosków.
\end{itemize}


\clearpage
\section*{Załączniki}

\addcontentsline{toc}{section}{Załączniki}

Do pracy załączono kod źródłowy przygotowanej aplikacji.

\clearpage


\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{4}
    % Wstęp
    \bibitem{python} https://www.python.org/. Dostęp 30.03.2023.
    \bibitem{pandas} https://pandas.pydata.org/. Dostęp 30.03.2023.
    \bibitem{numpy} https://numpy.org/. Dostęp 30.03.2023.
    \bibitem{scikit} https://scikit-learn.org/stable/. Dostęp 30.03.2023.
    \bibitem{easygui} https://easygui.sourceforge.net/. Dostęp 30.03.2023.
    \bibitem{uci} https://archive-beta.ics.uci.edu/. Dostęp 30.03.2023.
    \bibitem{kaggle} https://www.kaggle.com/datasets. Dostęp 30.03.2023.
    % Wprowadzenie
    \bibitem{fin} Sun Y., Shi Y., Zhang Z.: Finance Big Data: Management, Analysis, and Applications. International Journal of Electronic Commerce, 2019.
    \bibitem{med} Austin P., White I., Lee D., van Buuren S.: Missing Data in Clinical Research: A Tutorial on Multiple Imputation. The Canadian journal of cardiology vol. 37,9, 2020.
    \bibitem{pop} Balk D., Leyk S., Jones B., Montgomery M.R., Clark A.: Understanding urbanization: A study of census and satellite-derived urban classes in the United States, 1990-2010. PLOS ONE, 2018.
    \bibitem{net} Casas P., D'Alconzo A., Zseby T., Mellia M.: Big-DAMA: Big Data Analytics for Network Traffic Monitoring and Analysis. 2016.
    \bibitem{types} https://www.scribbr.com/statistics/missing-data/. Dostęp 30.03.2023.
    \bibitem{fisher} Fisher R. A.: The Goodness of Fit of Regression Formulae, and the Distribution of Regression Coefficients. Journal of the Royal Statistical Society, 1922.
    \bibitem{wilson} Wilson E. B.: Probable Inference, the Law of Succession, and Statistical Inference. Journal of the American Statistical Association, 1927.
    \bibitem{rubin} Rubin D. B.: Multiple Imputation for Nonresponse in Surveys. Wileys, John Wiley \& Sons, Indianapolis 198z.
    \bibitem{multi} Bayzid S., Bhattacharjee A.: Machine learning based imputation techniques for estimating phylogenetic trees from incomplete distance matrices. BMC Genomics, 2019.
    \bibitem{impu} https://towardsdatascience.com/implementation-and-limitations-of-imputation-methods-b6576bf31a6c. Dostęp 30.03.2023.
    \bibitem{bigata} https://www.oracle.com/pl/big-data/what-is-big-data/. Dostęp 30.03.2023.
    \bibitem{ogd} https://www.oecd.org/gov/digital-government/open-government-data.htm. Dostęp 30.03.2023.
    \bibitem{ogdpl} https://dane.gov.pl/pl. Dostęp 30.03.2023.
    \bibitem{future} Adnan F., Jamaludin K., Muhamad W., Miskon S.: A Review of Current Publications Trend on Missing Data Imputation Over Three Decades: Direction and Future Research. 2021.
    % Narzędzia
    \bibitem{abc} Geurts L., Meertens L., Pemberton S.: ABC Programmer's Handbook. Bosko Books, Londyn 2005.
    \bibitem{python2} https://www.artima.com/articles/the-making-of-python. Dostęp 30.03.2023.
    \bibitem{python3} Lutz M.: Learning Python, 5th Edition. O'Reilly Media Inc, Sebastopol 2013.
    \bibitem{ide} https://www.redhat.com/en/topics/middleware/what-is-ide. Dostęp 30.03.2023.
    \bibitem{vsc} https://code.visualstudio.com/. Dostęp 30.03.2023.
    \bibitem{vsc2} Johnson B.: Visual Studio Code: End-to-End Editing and Debugging Tools for Web Developers. John Wiley \& Sons, Indianapolis 2019.
    \bibitem{github} https://github.com/. Dostęp 30.03.2023.
    \bibitem{github2} Chacon S., Straub B.: Pro Git 2nd ed. Apress, 2014.
    \bibitem{git} Laster B.: Professional Git. John Wiley \& Sons, Indianapolis 2017.
    % Biblioteki
    \bibitem{pandas2} Petrou T.: Pandas Cookbook: Recipes for Scientific Computing, Time Series Analysis and Data Visualization using Python. Packt Publishing, Birmingham 2017.
    \bibitem{numeric} https://pypi.org/project/Numeric/. Dostęp 30.03.2023.
    \bibitem{numarray} https://pypi.org/project/numarray/. Dostęp 30.03.2023.
    \bibitem{numpy2} Ranjani J., Sheela A., Meena K. P.: "Combination of NumPy, SciPy and Matplotlib/Pylab -a good alternative methodology to MATLAB - A Comparative analysis" 2019 1st International Conference on Innovations in Information and Communication Technology (ICIICT), Chennai 2019
    \bibitem{numpy3} McKinney W.: Python for Data Analysis. O'Reilly Media Inc, Sebastopol 2012.
    \bibitem{inria} https://www.inria.fr/en. Dostęp 30.03.2023.
    \bibitem{tkinter} https://docs.python.org/3/library/tkinter.html. Dostęp 30.03.2023.
    % Źródła danych
    \bibitem{googlesearch} https://datasetsearch.research.google.com/. Dostęp 30.03.2023.
    \bibitem{googlesearch2} Noy N., Burgess M., Brickley D.: Google Dataset Search: Building a search engine for datasets in an open Web ecosystem. WebConf'2019, San Francisco 2019
    \bibitem{adult} https://archive-beta.ics.uci.edu/dataset/2/adult. Dostęp 30.03.2023.
    \bibitem{stock} www.kaggle.com/datasets/mattiuzc/stock-exchange-data. Dostęp 30.03.2023.
    \bibitem{autopy} https://pypi.org/project/auto-py-to-exe/. Dostęp 30.03.2023.
    % Implementacja
    \bibitem{wybZag} Brański A.: Wybrane zagadnienia informatyki stosowanej. Oficyna Wydawnicza Politechniki Rzeszowskiej, Rzeszów 2020.
\end{thebibliography}

\clearpage


\makesummary

\end{document}
